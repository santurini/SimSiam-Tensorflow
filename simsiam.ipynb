{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B47ABIDxuyzf",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title imports\n",
        "%pip install -q einops\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, losses\n",
        "from einops import *\n",
        "from einops.layers.tensorflow import EinMix as Mix\n",
        "\n",
        "path = '../input/intel-image-classification'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title contrastive loss\n",
        "class ContrastiveLoss(losses.Loss):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def call(self, p, z):\n",
        "    p = tf.math.l2_normalize(p, axis=1)\n",
        "    z = tf.math.l2_normalize(z, axis=1)\n",
        "    return - reduce(einsum(p, z, 'b d, b d -> b'), 'b -> 1', 'mean')"
      ],
      "metadata": {
        "id": "XmtqtuABvo4R",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title backbone\n",
        "\n",
        "#@title convolution\n",
        "class Conv(layers.Layer):\n",
        "    def __init__(self, filters, kernel, *args, **kwargs):\n",
        "        super().__init__(*args)\n",
        "        self.conv = layers.Conv2D(filters, kernel, **kwargs, padding='same', use_bias=False)\n",
        "        self.ln = layers.BatchNormalization()\n",
        "        self.selu = layers.Activation('relu')\n",
        "        \n",
        "    def call(self, inputs, training=False):\n",
        "        inputs = self.conv(inputs, training=training)\n",
        "        inputs = self.ln(inputs, training=training)\n",
        "        inputs = self.selu(inputs)\n",
        "        \n",
        "        return inputs\n",
        "\n",
        "#@title residual connection\n",
        "class ResidualConnection(layers.Layer):\n",
        "    def __init__(self, filters, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.conv1 = Conv(filters, 3) \n",
        "        self.conv2 = Conv(filters*2, 3) # double the filters\n",
        "    \n",
        "    def call(self, inputs, training=False):\n",
        "        residual = inputs\n",
        "        inputs = self.conv1(inputs, training=training)\n",
        "        inputs = self.conv2(inputs, training=training)\n",
        "        return inputs + residual\n",
        "\n",
        "#@title backbone\n",
        "class convnet(tf.keras.Model):\n",
        "    def __init__(self, classes, filters):\n",
        "        super().__init__()\n",
        "        self.conv_1 = Conv(filters*2, 1, name='conv1')\n",
        "        self.res_1 = ResidualConnection(filters, name='res1')\n",
        "        self.conv_2 = Conv(filters*4, 1, name='conv2')\n",
        "        self.res_2 = ResidualConnection(filters*2, name='res2') \n",
        "        self.conv_3 = Conv(filters*2, 1, name='conv3')\n",
        "        self.globalpool = layers.GlobalMaxPooling2D(name='globalpool')\n",
        "        self.fc = layers.Dense(classes, activation='softmax', name='fc')\n",
        "        self.maxpool = layers.MaxPooling2D()\n",
        "        \n",
        "    def call(self, inputs, training=False):\n",
        "        inputs = self.maxpool(self.conv_1(inputs, training=training))\n",
        "        inputs = self.res_1(inputs, training=training)\n",
        "        inputs = self.maxpool(self.conv_2(inputs, training=training))\n",
        "        inputs = self.res_2(inputs, training=training)\n",
        "        inputs = self.maxpool(self.conv_3(inputs, training=training))\n",
        "        inputs = self.globalpool(inputs)\n",
        "        output = self.fc(inputs, training=training)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "4NcEAzdfvFtO",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title projector\n",
        "class Projector(layers.Layer):\n",
        "  def __init__(self, dim):\n",
        "    super().__init__()\n",
        "    self.dim = dim\n",
        "  \n",
        "  def build(self, shape):\n",
        "    self.mlp = tf.keras.Sequential([\n",
        "        Mix('b i -> b j', weight_shape='i j', i=shape[1], j=shape[1]),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "        Mix('b i -> b j', weight_shape='i j', i=shape[1], j=shape[1]),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "        Mix('b i -> b d', weight_shape='i d', i=shape[1], d=self.dim),  \n",
        "    ], name='projector')\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    return self.mlp(inputs, training=training)      "
      ],
      "metadata": {
        "id": "lVPh_z4X3iox",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title predictor\n",
        "class Predictor(layers.Layer):\n",
        "  def __init__(self, pred_dim):\n",
        "    super().__init__()\n",
        "    self.pred_dim = pred_dim\n",
        "  \n",
        "  def build(self, shape):\n",
        "    self.mlp = tf.keras.Sequential([\n",
        "        Mix('b i -> b d', weight_shape='i d', i=shape[1], d=self.pred_dim),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.ReLU(),\n",
        "        Mix('b d -> b i', weight_shape='d i', d=self.pred_dim, i=shape[1]),\n",
        "    ], name='predictor')\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    return self.mlp(inputs, training=training)  "
      ],
      "metadata": {
        "id": "9GzrF0nb6ovo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title simsiam\n",
        "class SimSiam(tf.keras.Model):\n",
        "  def __init__(self, dim, pred_dim):\n",
        "    super().__init__()\n",
        "    self.encoder = convnet(dim, 64)\n",
        "    self.encoder.fc = Projector(dim)\n",
        "    self.predictor = Predictor(dim)\n",
        "    self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    x1, x2 = inputs[0][0], inputs[0][1]\n",
        "    z1 = self.encoder(x1, training=training) # n x d\n",
        "    z2 = self.encoder(x2, training=training) # n x d\n",
        "    p1 = self.predictor(z1, training=training)\n",
        "    p2 = self.predictor(z2, training=training)\n",
        "    return p1, p2, tf.stop_gradient(z1), tf.stop_gradient(z2)\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    with tf.GradientTape() as tape:\n",
        "      p1, p2, z1, z2 = self(inputs, training=True)\n",
        "      loss = self.compiled_loss(p1, z2)*0.5 + self.compiled_loss(p2, z1)*0.5\n",
        "      trainable_vars = self.trainable_variables\n",
        "      gradients = tape.gradient(loss, trainable_vars)\n",
        "      self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "      self.loss_tracker.update_state(loss)\n",
        "      return {\"loss\": self.loss_tracker.result()}\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "    return [self.loss_tracker]"
      ],
      "metadata": {
        "id": "X8GFs-Gb7Mtr",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title data preparation\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(path + \"/seg_train/seg_train\", image_size=(64, 64), label_mode='int', batch_size=8)\n",
        "test_ds = tf.keras.utils.image_dataset_from_directory(path + \"/seg_test/seg_test\", label_mode='int', image_size=(64, 64), batch_size=1)\n",
        "\n",
        "def augment(images, labels):\n",
        "    x1, x2 = tf.image.random_flip_left_right(images), tf.image.random_flip_left_right(images)\n",
        "    x1, x2 = tf.image.random_flip_up_down(x1), tf.image.random_flip_up_down(x2)\n",
        "    x1, x2 = tf.image.rot90(x1), tf.image.rot90(x2)\n",
        "    x1, x2 = tf.image.random_brightness(x1, max_delta=0.8), tf.image.random_brightness(x2, max_delta=0.8)\n",
        "    x1, x2 = tf.image.random_contrast(x1, lower=1-0.8, upper=1+0.8), tf.image.random_contrast(x2, lower=1-0.8, upper=1+0.8)\n",
        "    x1, x2 = tf.image.random_saturation(x1, lower=1-0.8, upper=1+0.8), tf.image.random_saturation(x2, lower=1-0.8, upper=1+0.8)\n",
        "    x1, x2 = tf.image.random_hue(x1, max_delta=0.2), tf.image.random_hue(x2, max_delta=0.2)\n",
        "    return (x1/255, x2/255), labels\n",
        "\n",
        "train_ds = (\n",
        "    train_ds\n",
        "    .cache()\n",
        "    .shuffle(1024, seed=0)\n",
        "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
        "    .prefetch(AUTOTUNE)\n",
        ")\n",
        "\n",
        "test_ds = test_ds.map(lambda x, y: (x/255.0, y))\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "eYai6gFfiszG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title training - contrastive learning\n",
        "simsiam = SimSiam(dim=2048, pred_dim=512)\n",
        "epochs = 100\n",
        "\n",
        "#@title loss and optimizer\n",
        "loss = ContrastiveLoss()\n",
        "scheduler = tf.keras.optimizers.schedules.CosineDecay(0.05, 500)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=scheduler, momentum=0.9, decay=1e-04)\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=15)\n",
        "\n",
        "#@title compile and train\n",
        "simsiam.compile(optimizer=optimizer, loss=loss)\n",
        "simsiam.fit(train_ds, epochs=epochs, callbacks=[early_stop])"
      ],
      "metadata": {
        "id": "dGvHjv8x9z_o",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title testing - image classification\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(path + \"/seg_train/seg_train\", image_size=(64, 64), label_mode='int', batch_size=8)\n",
        "train_ds = train_ds.cache().shuffle(1024, seed=0).map(lambda x, y: (x/255.0, y), num_parallel_calls=AUTOTUNE).prefetch(AUTOTUNE)\n",
        "\n",
        "classes = 6\n",
        "convnet = simsiam.encoder\n",
        "convnet.fc = layers.Dense(classes, activation='softmax', name='fc')\n",
        "scheduler = tf.keras.optimizers.schedules.CosineDecay(0.01, 500)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=scheduler, momentum=0.9, decay=1e-04)\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
        "\n",
        "\n",
        "convnet.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "convnet.fit(train_ds, validation_data=test_ds, epochs=50, callbacks=[early_stop])"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HI6dmeFUCNbq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}